{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sandy-lee29/app-review/blob/main/review_scraper.ipynb)\n"
      ],
      "metadata": {
        "id": "_DIdb74MGhJC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Week 1 : App review Data Extraction and Clean Up\n",
        "Industry: Music\n",
        "\n",
        "Companies Analyzed:\n",
        "- Apple Music\n",
        "- Amazon Music\n",
        "- Spotify\n",
        "- Youtube Music"
      ],
      "metadata": {
        "id": "SWE48_3D4IvD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk emoji textblob\n",
        "import pandas as pd\n",
        "import csv\n",
        "import re\n",
        "import emoji\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import pos_tag\n",
        "from textblob import TextBlob\n",
        "from datetime import datetime, timedelta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEbjELEF6gC6",
        "outputId": "3f79cb7d-4c18-4e9e-b425-5eafab5d9a70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Collecting emoji\n",
            "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.11/dist-packages (0.19.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emoji\n",
            "Successfully installed emoji-2.14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Google App Store Data Extraction"
      ],
      "metadata": {
        "id": "c99x1-ID6CGF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTzp-JxX4EAc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b4b372e-de6f-452c-ba65-646114216235"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m41.0/50.2 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m540.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q google-play-scraper\n",
        "import pandas as pd\n",
        "from google_play_scraper import reviews, Sort"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_reviews(package_name: str, n_reviews: int = 1000) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Fetch Google Play reviews for a given package using NEWEST and MOST_RELEVANT sorting.\n",
        "\n",
        "    Args:\n",
        "        package_name (str): The package name of the app on Google Play.\n",
        "        n_reviews (int): The maximum number of reviews per sorting method (default: 1000).\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame containing raw review data.\n",
        "    \"\"\"\n",
        "    # Fetch newest reviews (NEWEST)\n",
        "    newest_reviews, _ = reviews(\n",
        "        package_name,\n",
        "        lang='en',\n",
        "        country='us',\n",
        "        sort=Sort.NEWEST,\n",
        "        count=n_reviews,\n",
        "        filter_score_with=None\n",
        "    )\n",
        "\n",
        "    # Fetch most relevant reviews (MOST_RELEVANT)\n",
        "    relevant_reviews, _ = reviews(\n",
        "        package_name,\n",
        "        lang='en',\n",
        "        country='us',\n",
        "        sort=Sort.MOST_RELEVANT,\n",
        "        count=n_reviews,\n",
        "        filter_score_with=None\n",
        "    )\n",
        "\n",
        "    # Combine both datasets\n",
        "    all_reviews_data = newest_reviews + relevant_reviews\n",
        "    reviews_df = pd.DataFrame(all_reviews_data)\n",
        "\n",
        "    return reviews_df\n",
        "\n",
        "def clean_reviews(df: pd.DataFrame, app_name: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Clean and preprocess the review data.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): Raw review DataFrame.\n",
        "        app_name (str): Name of the app.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Cleaned DataFrame with only necessary columns.\n",
        "                    Final columns: review_id, review, rating, time, company, data_source, app_name.\n",
        "    \"\"\"\n",
        "    if df.empty:\n",
        "        return df  # If no reviews, return empty DataFrame\n",
        "\n",
        "    # Select only the necessary columns and make a copy\n",
        "    df = df[[\"reviewId\", \"content\", \"score\", \"at\"]].copy()\n",
        "\n",
        "    # Rename columns\n",
        "    df.rename(columns={\n",
        "        \"reviewId\": \"review_id\",\n",
        "        \"content\": \"review\",\n",
        "        \"score\": \"rating\",\n",
        "        \"at\": \"time\"\n",
        "    }, inplace=True)\n",
        "\n",
        "    # Add columns for the app name and data source\n",
        "    df[\"company\"] = app_name           # Add the app name as company\n",
        "    df[\"data_source\"] = \"Android\"      # Indicate the data source\n",
        "\n",
        "    # Data Cleaning: Clean review text, convert rating to numeric, and time to datetime\n",
        "    df[\"review\"] = df[\"review\"].astype(str)\\\n",
        "                    .str.replace(\",\", \" \", regex=False)\\\n",
        "                    .str.replace(\"\\n\", \" \", regex=False)\\\n",
        "                    .str.strip()\n",
        "    df[\"rating\"] = pd.to_numeric(df[\"rating\"], errors='coerce')\n",
        "    df[\"time\"] = pd.to_datetime(df[\"time\"], errors='coerce')\n",
        "\n",
        "    # Remove rows with missing values in critical columns\n",
        "    df.dropna(subset=[\"review\", \"rating\", \"time\"], inplace=True)\n",
        "\n",
        "    # Keep only valid ratings (1 to 5)\n",
        "    df = df[(df[\"rating\"] >= 1) & (df[\"rating\"] <= 5)]\n",
        "\n",
        "    # Remove duplicate reviews based on 'review_id'\n",
        "    df.drop_duplicates(subset=[\"review_id\"], inplace=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "def scrape_multiple_apps(apps: dict, n_reviews: int = 1000, output_filename: str = \"google_play_reviews.csv\"):\n",
        "    \"\"\"\n",
        "    Extract and save Google Play reviews for multiple apps.\n",
        "\n",
        "    Args:\n",
        "        apps (dict): Dictionary with app names as keys and package names as values.\n",
        "        n_reviews (int): Number of reviews per sorting method.\n",
        "        output_filename (str): CSV filename to save the reviews (default: \"google_play_reviews.csv\").\n",
        "    \"\"\"\n",
        "    all_reviews = []\n",
        "\n",
        "    for app_name, package_name in apps.items():\n",
        "        print(f\"Scraping reviews for {app_name}...\")\n",
        "        raw_reviews = fetch_reviews(package_name, n_reviews)\n",
        "        cleaned_reviews = clean_reviews(raw_reviews, app_name)\n",
        "        all_reviews.append(cleaned_reviews)\n",
        "\n",
        "    # Combine all app reviews into a single DataFrame\n",
        "    final_df = pd.concat(all_reviews, ignore_index=True)\n",
        "\n",
        "    # Save to CSV\n",
        "    final_df.to_csv(output_filename, index=False)\n",
        "    print(f\"All reviews saved successfully to {output_filename}! 🎉\")\n",
        "\n",
        "# Dictionary of top 4 Music Apps on Google Play\n",
        "apps = {\n",
        "    \"Apple Music\": \"com.apple.android.music\",\n",
        "    \"Spotify\": \"com.spotify.music\",\n",
        "    \"Amazon Music\": \"com.amazon.mp3\",\n",
        "    \"YouTube Music\": \"com.google.android.apps.youtube.music\",\n",
        "}\n",
        "\n",
        "scrape_multiple_apps(apps)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G179M4gOKxMY",
        "outputId": "18d5251a-cfdd-4e3a-d5e1-94d01a215499"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping reviews for Apple Music...\n",
            "Scraping reviews for Spotify...\n",
            "Scraping reviews for Amazon Music...\n",
            "Scraping reviews for YouTube Music...\n",
            "All reviews saved successfully to google_play_reviews.csv! 🎉\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "google_reviews = pd.read_csv('google_play_reviews.csv')"
      ],
      "metadata": {
        "id": "sPoGpdqgEecM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "google_reviews.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "-NE63kovEslO",
        "outputId": "11c1dba4-db63-47c1-aa17-f0e7e80ff5bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "review_id      7474\n",
              "review         7474\n",
              "rating         7474\n",
              "time           7474\n",
              "company        7474\n",
              "data_source    7474\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>review_id</th>\n",
              "      <td>7474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>review</th>\n",
              "      <td>7474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rating</th>\n",
              "      <td>7474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>time</th>\n",
              "      <td>7474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>company</th>\n",
              "      <td>7474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>data_source</th>\n",
              "      <td>7474</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Apple App Store Data Extraction"
      ],
      "metadata": {
        "id": "OOhfVDrWA5GR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q app-store-scraper\n",
        "from app_store_scraper import AppStore"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2cxhln6CrUo",
        "outputId": "3a01c5d0-c3b7-412f-fdd3-359d1576d0e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting app-store-scraper\n",
            "  Downloading app_store_scraper-0.3.5-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting requests==2.23.0 (from app-store-scraper)\n",
            "  Downloading requests-2.23.0-py2.py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting chardet<4,>=3.0.2 (from requests==2.23.0->app-store-scraper)\n",
            "  Downloading chardet-3.0.4-py2.py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting idna<3,>=2.5 (from requests==2.23.0->app-store-scraper)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 (from requests==2.23.0->app-store-scraper)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.1/41.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests==2.23.0->app-store-scraper) (2025.1.31)\n",
            "Downloading app_store_scraper-0.3.5-py3-none-any.whl (8.3 kB)\n",
            "Downloading requests-2.23.0-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.0/128.0 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: chardet, urllib3, idna, requests, app-store-scraper\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.3.0\n",
            "    Uninstalling urllib3-2.3.0:\n",
            "      Successfully uninstalled urllib3-2.3.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.23.0 which is incompatible.\n",
            "tweepy 4.15.0 requires requests<3,>=2.27.0, but you have requests 2.23.0 which is incompatible.\n",
            "sentry-sdk 2.22.0 requires urllib3>=1.26.11, but you have urllib3 1.25.11 which is incompatible.\n",
            "distributed 2024.11.2 requires urllib3>=1.26.5, but you have urllib3 1.25.11 which is incompatible.\n",
            "bigframes 1.37.0 requires requests>=2.27.1, but you have requests 2.23.0 which is incompatible.\n",
            "sphinx 8.1.3 requires requests>=2.30.0, but you have requests 2.23.0 which is incompatible.\n",
            "google-genai 0.8.0 requires requests<3.0.0dev,>=2.28.1, but you have requests 2.23.0 which is incompatible.\n",
            "yfinance 0.2.54 requires requests>=2.31, but you have requests 2.23.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed app-store-scraper-0.3.5 chardet-3.0.4 idna-2.10 requests-2.23.0 urllib3-1.25.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_apple_reviews(app_name: str, app_id: str, n_reviews: int = 1000, **kwargs) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Fetches Apple App Store reviews for the given app.\n",
        "\n",
        "    Args:\n",
        "        app_name (str): The name of the app.\n",
        "        app_id (str): The unique identifier of the app.\n",
        "        n_reviews (int): The number of reviews to fetch (default: 1000).\n",
        "        **kwargs: Additional options:\n",
        "            - sleep_milliseconds (int): Delay between requests in milliseconds (default: 2000ms).\n",
        "            - lang (str): Review language (default: 'en').\n",
        "            - country (str): Country code (default: 'us').\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame containing the fetched review data.\n",
        "    \"\"\"\n",
        "    # Set default parameters\n",
        "    default_params = {\n",
        "        'sleep_milliseconds': 2000,\n",
        "        'lang': 'en',\n",
        "        'country': 'us',\n",
        "        'count': n_reviews\n",
        "    }\n",
        "    params = {**default_params, **kwargs}\n",
        "\n",
        "    # Initialize the AppStore scraper\n",
        "    app = AppStore(\n",
        "        country=params['country'],\n",
        "        app_id=app_id,\n",
        "        app_name=app_name\n",
        "    )\n",
        "\n",
        "    # Fetch reviews (limit the number using the how_many parameter)\n",
        "    app.review(\n",
        "        how_many=params['count'],\n",
        "        sleep=params['sleep_milliseconds'] / 1000  # Convert milliseconds to seconds\n",
        "    )\n",
        "\n",
        "    # Convert the result to a DataFrame and return\n",
        "    return pd.DataFrame(app.reviews)\n",
        "\n",
        "def clean_apple_reviews(df: pd.DataFrame, app_name: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Cleans and processes Apple App Store review data.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The raw review DataFrame.\n",
        "        app_name (str): The name of the app.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A cleaned DataFrame containing only the necessary columns,\n",
        "                      with an empty 'review_id' column and the 'app_name' column added.\n",
        "    \"\"\"\n",
        "    if df.empty:\n",
        "        return df  # Return as is if no reviews are available\n",
        "\n",
        "    # Select necessary columns (usually \"review\", \"rating\", and \"date\" are provided)\n",
        "    expected_columns = [\"review\", \"rating\", \"date\"]\n",
        "    available_cols = [col for col in expected_columns if col in df.columns]\n",
        "    df = df[available_cols].copy()\n",
        "\n",
        "    # Rename the 'date' column to 'time' if it exists\n",
        "    if 'date' in df.columns:\n",
        "        df.rename(columns={'date': 'time'}, inplace=True)\n",
        "\n",
        "    # Clean the review text: remove commas, newlines, and trim whitespace\n",
        "    if 'review' in df.columns:\n",
        "        df['review'] = df['review'].astype(str)\\\n",
        "                            .str.replace(\",\", \" \", regex=False)\\\n",
        "                            .str.replace(\"\\n\", \" \", regex=False)\\\n",
        "                            .str.strip()\n",
        "\n",
        "    # Convert ratings to numeric values\n",
        "    if 'rating' in df.columns:\n",
        "        df['rating'] = pd.to_numeric(df['rating'], errors='coerce')\n",
        "\n",
        "    # Convert the time column to datetime\n",
        "    if 'time' in df.columns:\n",
        "        df['time'] = pd.to_datetime(df['time'], errors='coerce')\n",
        "\n",
        "    # Drop rows with missing required values\n",
        "    df.dropna(subset=['review', 'rating', 'time'], inplace=True)\n",
        "\n",
        "    # Keep only valid ratings (1 to 5)\n",
        "    df = df[(df['rating'] >= 1) & (df['rating'] <= 5)]\n",
        "\n",
        "    # Remove duplicate reviews based on the review text\n",
        "    df.drop_duplicates(subset=['review'], inplace=True)\n",
        "\n",
        "    # Add columns: create an empty 'review_id', add app name and data source columns\n",
        "    df[\"review_id\"] = \"\"               # Create review_id column (empty)\n",
        "    df[\"company\"] = app_name\n",
        "    df[\"data_source\"] = \"IOS\"           # Indicate the data source\n",
        "\n",
        "    # Optionally, reorder the columns\n",
        "    final_columns = [\"review_id\", \"review\", \"rating\", \"time\", \"company\", \"data_source\"]\n",
        "    df = df[final_columns]\n",
        "\n",
        "    return df\n",
        "\n",
        "def scrape_multiple_apple_apps(apps: dict, n_reviews: int = 1000, output_filename: str = \"apple_app_reviews.csv\"):\n",
        "    \"\"\"\n",
        "    Fetches Apple App Store reviews for multiple apps and saves them to a CSV file.\n",
        "\n",
        "    Args:\n",
        "        apps (dict): A dictionary with app names as keys and app IDs as values.\n",
        "        n_reviews (int): The number of reviews to fetch per app (default: 1000).\n",
        "        output_filename (str): The CSV filename for saving the reviews.\n",
        "    \"\"\"\n",
        "    all_reviews = []\n",
        "\n",
        "    for app_name, app_id in apps.items():\n",
        "        print(f\"Scraping reviews for {app_name}...\")\n",
        "        # Fetch review data\n",
        "        raw_reviews = fetch_apple_reviews(app_name, app_id, n_reviews=n_reviews)\n",
        "        # Clean the review data\n",
        "        cleaned_reviews = clean_apple_reviews(raw_reviews, app_name)\n",
        "        all_reviews.append(cleaned_reviews)\n",
        "\n",
        "    # Combine all app reviews into a single DataFrame\n",
        "    final_df = pd.concat(all_reviews, ignore_index=True)\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    final_df.to_csv(output_filename, index=False)\n",
        "    print(f\"All reviews saved successfully to {output_filename}! 🎉\")\n",
        "\n",
        "# Dictionary of app names and their corresponding Apple App Store IDs\n",
        "apps = {\n",
        "    \"Apple Music\": \"1108187390\",\n",
        "    \"Spotify\": \"324684580\",\n",
        "    \"Amazon Music\": \"571800810\",\n",
        "    \"YouTube Music\": \"1017492454\",\n",
        "}\n",
        "\n",
        "# Start scraping reviews\n",
        "scrape_multiple_apple_apps(apps, n_reviews=1000)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78nTvkIiL6Lq",
        "outputId": "ef86c7d2-a534-4fd0-b1b0-b386129e2837"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping reviews for Apple Music...\n",
            "Scraping reviews for Spotify...\n",
            "Scraping reviews for Amazon Music...\n",
            "Scraping reviews for YouTube Music...\n",
            "All reviews saved successfully to apple_app_reviews.csv! 🎉\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "apple_reviews = pd.read_csv('apple_app_reviews.csv')"
      ],
      "metadata": {
        "id": "u9amW00hGh3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "apple_reviews.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "O2toKAlpGl0l",
        "outputId": "7f65f41b-447b-4bf5-9dd8-adc34e6f8c09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "review_id         0\n",
              "review         4000\n",
              "rating         4000\n",
              "time           4000\n",
              "company        4000\n",
              "data_source    4000\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>review_id</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>review</th>\n",
              "      <td>4000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rating</th>\n",
              "      <td>4000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>time</th>\n",
              "      <td>4000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>company</th>\n",
              "      <td>4000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>data_source</th>\n",
              "      <td>4000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Combining Google + Apple Review and Preprocessing"
      ],
      "metadata": {
        "id": "x0Eekpd-I10N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    # Download necessary NLTK resources (downloads will be skipped if already present)\n",
        "    nltk.download('stopwords', quiet=True)\n",
        "    nltk.download('punkt', quiet=True)\n",
        "    nltk.download('averaged_perceptron_tagger', quiet=True)\n",
        "    nltk.download('averaged_perceptron_tagger_eng', quiet=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCryz9vmJMkB",
        "outputId": "94c37ed4-f073-4444-cacb-6dfc76bea1eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_reviews = pd.concat([google_reviews, apple_reviews], ignore_index=True)"
      ],
      "metadata": {
        "id": "qrLtKlf1JiW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_combined_reviews(df: pd.DataFrame, review_column: str = 'review') -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Preprocesses review texts in the given DataFrame by applying the following steps:\n",
        "      1. Convert text to lowercase.\n",
        "      2. Remove emojis.\n",
        "      3. Remove special characters (e.g., punctuation and symbols).\n",
        "      4. Remove meaningless reviews (e.g., reviews containing only adjectives or very short reviews).\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): A DataFrame containing combined reviews from Google and Apple.\n",
        "        review_column (str): The name of the column containing review texts (default is 'review').\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame with preprocessed review texts. Rows with empty reviews after processing are removed.\n",
        "    \"\"\"\n",
        "\n",
        "    def remove_emojis(text: str) -> str:\n",
        "        return emoji.replace_emoji(text, replace=\"\")  # Remove emojis\n",
        "\n",
        "    def remove_special_chars(text: str) -> str:\n",
        "        return re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)  # Remove all non-alphanumeric characters (except spaces)\n",
        "\n",
        "    def remove_meaningless_reviews(text: str) -> str:\n",
        "        words = text.split()\n",
        "        pos_tags = pos_tag(words)  # Get part-of-speech tags\n",
        "        # Extract adjectives (POS tags starting with 'JJ')\n",
        "        adj_only = [word for word, tag in pos_tags if tag.startswith(\"JJ\")]\n",
        "        # Remove review if it only contains adjectives (with 5 or fewer words) or is very short (6 or fewer words)\n",
        "        if (len(adj_only) == len(words) and len(words) <= 5) or len(words) <= 6:\n",
        "            return \"\"\n",
        "        return text\n",
        "\n",
        "    def preprocess_review(text: str) -> str:\n",
        "        if isinstance(text, str):\n",
        "            text = text.lower()  # Convert to lowercase\n",
        "            text = remove_emojis(text)\n",
        "            text = remove_special_chars(text)\n",
        "            text = remove_meaningless_reviews(text)\n",
        "        return text\n",
        "\n",
        "    # Apply the preprocessing to the specified review column\n",
        "    df[review_column] = df[review_column].astype(str).apply(preprocess_review)\n",
        "\n",
        "    # Remove any rows with empty reviews after processing\n",
        "    df = df[df[review_column].str.strip() != \"\"]\n",
        "\n",
        "    return df\n",
        "\n"
      ],
      "metadata": {
        "id": "WHbT_wE9ItHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_reviews = preprocess_combined_reviews(combined_reviews, review_column=\"review\")\n",
        "processed_reviews.to_csv(\"cleaned_reviews.csv\", index=False)\n",
        "print(\"✅ Review preprocessing complete! Cleaned data saved as 'cleaned_reviews.csv'\")\n"
      ],
      "metadata": {
        "id": "WXo45cZiJzAC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d42e118-f68f-4a6a-eaf1-d59143c78deb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Review preprocessing complete! Cleaned data saved as 'cleaned_reviews.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_reviews.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "ceuibPZmJ8fR",
        "outputId": "df6ebf15-11f9-4f7a-fc17-756254313ac2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "review_id      5696\n",
              "review         9695\n",
              "rating         9695\n",
              "time           9695\n",
              "company        9695\n",
              "data_source    9695\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>review_id</th>\n",
              "      <td>5696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>review</th>\n",
              "      <td>9695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rating</th>\n",
              "      <td>9695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>time</th>\n",
              "      <td>9695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>company</th>\n",
              "      <td>9695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>data_source</th>\n",
              "      <td>9695</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}